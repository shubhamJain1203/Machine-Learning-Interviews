{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0df3cebe-01e5-4db5-af5b-da5ba0e6d0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor, Resize\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98f59527-3375-4de8-a9eb-4497ceb6631e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustumDataset(Dataset):\n",
    "    def __init__(self, root_dir, data_type= \"train\", transforms = None):\n",
    "        super().__init__()\n",
    "        self.root_dir = root_dir\n",
    "        self.img_dir = os.path.join(root_dir, \"train\", \"images\")\n",
    "        self.label_dir = os.path.join(root_dir, \"train\", \"labels\")\n",
    "        self.images = os.listdir(self.img_dir)\n",
    "        self.labels = os.listdir(self.label_dir)\n",
    "        self.valid_data = self._remove_unlabeled()\n",
    "        self.transforms = transforms\n",
    "\n",
    "\n",
    "    def _remove_unlabeled(self):\n",
    "        valid_pairs = []\n",
    "        for image in self.images:\n",
    "            label = image.replace(\".jpg\", \".txt\")\n",
    "            if label in self.labels:\n",
    "                valid_pairs.append([image,label])\n",
    "        return valid_pairs\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image_path = os.path.join(self.img_dir , self.valid_data[idx][0])\n",
    "        label_path = os.path.join(self.label_dir , self.valid_data[idx][1])\n",
    "\n",
    "        image = Image.open(image_path)\n",
    "        labels = []\n",
    "    \n",
    "        with open(label_path, \"r\") as file:\n",
    "            for line in file:\n",
    "                c_bbox = list(map(float,line.strip().split()))\n",
    "                labels.append(c_bbox)\n",
    "                \n",
    "        if len(labels) > 5: \n",
    "            labels = labels[:5]\n",
    "        elif len(labels)<5:\n",
    "            n = 5-len(labels)\n",
    "            labels.extend(n*[[0,0,0,0,0]])\n",
    "\n",
    "            \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "            labels = self.target_transform(image, labels)\n",
    "\n",
    "        return image, labels\n",
    "\n",
    "    def target_transform(self,image,labels):\n",
    "        _, height, width = image.shape\n",
    "\n",
    "        for label in labels:\n",
    "            label[1] /= width\n",
    "            label[2] /= height\n",
    "            label[3] /= width\n",
    "            label[4] /= height\n",
    "        if self.transforms: \n",
    "            return torch.tensor(labels)\n",
    "        return labels\n",
    "        \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88e8993e-5e19-4647-9c95-9370c098ee09",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([Resize((64,64)), ToTensor()])\n",
    "train_dataset = CustumDataset(\"brain-tumor\", transforms =transform )\n",
    "tr_dataset, vl_datset = random_split(train_dataset, [0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03f55a62-f2c0-48fb-89da-a0b538865227",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLoader = DataLoader(train_dataset, batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65b6f95b-f26a-4c35-adfe-8c90ead2eb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv2d_1 = nn.Conv2d(in_channels = 1, out_channels = 64, kernel_size = 3) # input dim = 64*64\n",
    "        self.conv2d_2 = nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3) \n",
    "        self.conv2d_3 = nn.Conv2d(in_channels = 128, out_channels = 64, kernel_size = 3) \n",
    "        self.conv2d_4 = nn.Conv2d(in_channels = 64, out_channels = 32, kernel_size = 3)\n",
    "        self.fc1 = nn.Linear(32*13*13, 16)\n",
    "        self.fc2 = nn.Linear(16, 1)\n",
    "        self.maxpool  = nn.MaxPool2d(2,2)\n",
    "        self.activation1 = nn.ReLU()\n",
    "        self.activation2 = nn.Sigmoid()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.activation1(self.conv2d_1(x)) #dimensions in = 64*1*64*64, out = 64*64*62*62\n",
    "        x = self.activation1(self.conv2d_2(x))  # in = 64*64*62*62, out = 64*128*60*60\n",
    "        x = self.maxpool(x) # in =  64*128*60*60 out = 64*128*30*30\n",
    "        x = self.activation1(self.conv2d_3(x)) # in = 64*128*30*30, out = 64*64*28*28\n",
    "        x = self.activation1(self.conv2d_4(x)) # in = 64*64*28*28, out = 64*32*26*26\n",
    "        x = self.maxpool(x) # in = 64*32*26*26 out = 64*32*13*13\n",
    "        x = x.view(x.size(0), -1)  # in = 64*32*13*13 out = 64* (32*13*13)\n",
    "        x = self.fc1(x) #64*16\n",
    "        x = self.activation2(self.fc2(x)) #64*1\n",
    "        return x\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c4b58b4-8277-452f-927a-0415492e2587",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b24df4b6-0185-468a-976c-63e0151086fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5e2659a-2720-4b2c-b9d2-775e86ba9ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Average Loss: 0.6922910170895713\n",
      "Epoch: 2, Average Loss: 0.6921563020774296\n",
      "Epoch: 3, Average Loss: 0.692342106785093\n",
      "Epoch: 4, Average Loss: 0.6927987209388188\n",
      "Epoch: 5, Average Loss: 0.6921010783740452\n",
      "Epoch: 6, Average Loss: 0.6921735533646175\n",
      "Epoch: 7, Average Loss: 0.6921478041580745\n",
      "Epoch: 8, Average Loss: 0.6919499678271157\n",
      "Epoch: 9, Average Loss: 0.6918479076453617\n",
      "Epoch: 10, Average Loss: 0.6914678471429008\n",
      "Epoch: 11, Average Loss: 0.6915662331240517\n",
      "Epoch: 12, Average Loss: 0.6915951498917171\n",
      "Epoch: 13, Average Loss: 0.6908530465194157\n",
      "Epoch: 14, Average Loss: 0.6906189790793827\n",
      "Epoch: 15, Average Loss: 0.6904201039246151\n",
      "Epoch: 16, Average Loss: 0.6896374268191201\n",
      "Epoch: 17, Average Loss: 0.6893240213394165\n",
      "Epoch: 18, Average Loss: 0.6879519011293139\n",
      "Epoch: 19, Average Loss: 0.6866547380174909\n",
      "Epoch: 20, Average Loss: 0.6841665889535632\n",
      "Epoch: 21, Average Loss: 0.6818379887512752\n",
      "Epoch: 22, Average Loss: 0.6782106373991285\n",
      "Epoch: 23, Average Loss: 0.6762442886829376\n",
      "Epoch: 24, Average Loss: 0.6723291022436959\n",
      "Epoch: 25, Average Loss: 0.6764932998589107\n",
      "Epoch: 26, Average Loss: 0.6729775709765298\n",
      "Epoch: 27, Average Loss: 0.6628223146711077\n",
      "Epoch: 28, Average Loss: 0.6615818015166691\n",
      "Epoch: 29, Average Loss: 0.6508696334702628\n",
      "Epoch: 30, Average Loss: 0.6461070690836225\n",
      "Epoch: 31, Average Loss: 0.6686768276350838\n",
      "Epoch: 32, Average Loss: 0.6406637259892055\n",
      "Epoch: 33, Average Loss: 0.6353148179394859\n",
      "Epoch: 34, Average Loss: 0.6174804823739188\n",
      "Epoch: 35, Average Loss: 0.6352761047227042\n",
      "Epoch: 36, Average Loss: 0.6316769165652139\n",
      "Epoch: 37, Average Loss: 0.6247790072645459\n",
      "Epoch: 38, Average Loss: 0.6182565518787929\n",
      "Epoch: 39, Average Loss: 0.6016094003404889\n",
      "Epoch: 40, Average Loss: 0.6021958930151803\n",
      "Epoch: 41, Average Loss: 0.6038352506501334\n",
      "Epoch: 42, Average Loss: 0.5827204159327916\n",
      "Epoch: 43, Average Loss: 0.6119766746248517\n",
      "Epoch: 44, Average Loss: 0.5770882900272097\n",
      "Epoch: 45, Average Loss: 0.5685609536511558\n",
      "Epoch: 46, Average Loss: 0.5764012230294091\n",
      "Epoch: 47, Average Loss: 0.6049478607518333\n",
      "Epoch: 48, Average Loss: 0.5748641831534249\n",
      "Epoch: 49, Average Loss: 0.5477620554821832\n",
      "Epoch: 50, Average Loss: 0.5544531089918954\n",
      "Epoch: 51, Average Loss: 0.57337886095047\n",
      "Epoch: 52, Average Loss: 0.5426077118941716\n",
      "Epoch: 53, Average Loss: 0.5347040189164025\n",
      "Epoch: 54, Average Loss: 0.5191133575780051\n",
      "Epoch: 55, Average Loss: 0.5269649007490703\n",
      "Epoch: 56, Average Loss: 0.531827449798584\n",
      "Epoch: 57, Average Loss: 0.49811868369579315\n",
      "Epoch: 58, Average Loss: 0.4889049082994461\n",
      "Epoch: 59, Average Loss: 0.47735366438116345\n",
      "Epoch: 60, Average Loss: 0.4724905959197453\n",
      "Epoch: 61, Average Loss: 0.47149828927857534\n",
      "Epoch: 62, Average Loss: 0.4507923594542912\n",
      "Epoch: 63, Average Loss: 0.4361157715320587\n",
      "Epoch: 64, Average Loss: 0.4095715859106609\n",
      "Epoch: 65, Average Loss: 0.4190776539700372\n",
      "Epoch: 66, Average Loss: 0.4116931813103812\n",
      "Epoch: 67, Average Loss: 0.38683597104890005\n",
      "Epoch: 68, Average Loss: 0.3808372084583555\n",
      "Epoch: 69, Average Loss: 0.3569045045546123\n",
      "Epoch: 70, Average Loss: 0.38888279242174967\n",
      "Epoch: 71, Average Loss: 0.389112977044923\n",
      "Epoch: 72, Average Loss: 0.3525297375661986\n",
      "Epoch: 73, Average Loss: 0.31822649602379116\n",
      "Epoch: 74, Average Loss: 0.29783126392534803\n",
      "Epoch: 75, Average Loss: 0.2798239045909473\n",
      "Epoch: 76, Average Loss: 0.2382439449429512\n",
      "Epoch: 77, Average Loss: 0.23543304417814528\n",
      "Epoch: 78, Average Loss: 0.19917292573622294\n",
      "Epoch: 79, Average Loss: 0.1873908612344946\n",
      "Epoch: 80, Average Loss: 0.16810655061687743\n",
      "Epoch: 81, Average Loss: 0.14792295864650182\n",
      "Epoch: 82, Average Loss: 0.13298029825091362\n",
      "Epoch: 83, Average Loss: 0.24983298725315503\n",
      "Epoch: 84, Average Loss: 0.1866758745163679\n",
      "Epoch: 85, Average Loss: 0.14195559014167106\n",
      "Epoch: 86, Average Loss: 0.10034177212842874\n",
      "Epoch: 87, Average Loss: 0.0799819031464202\n",
      "Epoch: 88, Average Loss: 0.06326796047921691\n",
      "Epoch: 89, Average Loss: 0.07552662451884576\n",
      "Epoch: 90, Average Loss: 0.08778642270980137\n",
      "Epoch: 91, Average Loss: 0.11161533849579948\n",
      "Epoch: 92, Average Loss: 0.08032020327768155\n",
      "Epoch: 93, Average Loss: 0.055241083061056476\n",
      "Epoch: 94, Average Loss: 0.04292309171121035\n",
      "Epoch: 95, Average Loss: 0.038907945954373906\n",
      "Epoch: 96, Average Loss: 0.0548324729981167\n",
      "Epoch: 97, Average Loss: 0.1299144827893802\n",
      "Epoch: 98, Average Loss: 0.09414297142731291\n",
      "Epoch: 99, Average Loss: 0.04806121006341917\n",
      "Epoch: 100, Average Loss: 0.03176805377006531\n"
     ]
    }
   ],
   "source": [
    "num_itr = 100\n",
    "for epoch in range(1, 1 + num_itr):\n",
    "    cum_loss = 0  # Initialize cumulative loss for the epoch\n",
    "    num_batches = len(trainLoader)  # Number of batches per epoch\n",
    "\n",
    "    for idx, batch in enumerate(trainLoader):\n",
    "        images = batch[0]\n",
    "        raw_labels = batch[1]\n",
    "        all_labels = raw_labels[:, :, 0]\n",
    "        labels = (all_labels == 1).any(dim=1)\n",
    "        labels = labels.unsqueeze(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = loss_fn(output.float(), labels.float())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        cum_loss += loss.item()  # Add the scalar loss value (loss.item())\n",
    "\n",
    "    avg_loss = cum_loss / num_batches  # Average loss over all batches in the epoch\n",
    "    print(f\"Epoch: {epoch}, Average Loss: {avg_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e5373d-a810-43b1-81db-e68094a51ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964d55bc-cd33-42fc-8826-342c0e465875",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
